{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab | Data cleaning and wrangling\n",
    "\n",
    "For this lab, we will be using the same dataset we used in the previous labs. We recommend using the same notebook since you will be reusing the same variables you previous created and used in labs. \n",
    "\n",
    "### Instructions\n",
    "\n",
    "So far we have worked on `EDA`. This lab will focus on data cleaning and wrangling from everything we noticed before.\n",
    "\n",
    "**Hint for Categorical Variables**\n",
    "\n",
    "- You should deal with the categorical variables as shown below (for ordinal encoding, dummy code has been provided as well):\n",
    "\n",
    "```python\n",
    "# One hot to state\n",
    "# Ordinal to coverage\n",
    "# Ordinal to employmentstatus\n",
    "# Ordinal to location code\n",
    "# One hot to marital status\n",
    "# One hot to policy type\n",
    "# One hot to policy\n",
    "# One hot to renew offercustomer_df\n",
    "# One hot to sales channel\n",
    "# One hot vehicle class\n",
    "# Ordinal vehicle size\n",
    "\n",
    "data[\"coverage\"] = data[\"coverage\"].map({\"Basic\" : 0, \"Extended\" : 1, \"Premium\" : 2})\n",
    "# given that column \"coverage\" in the dataframe \"data\" has three categories:\n",
    "# \"basic\", \"extended\", and \"premium\" and values are to be represented in the same order.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. We will start with removing outliers. So far, we have discussed different methods to remove outliers. Use the one you feel more comfortable with, define a function for that. Use the function to remove the outliers and apply it to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No NaNs so just remove outliers (normalization method)\n",
    "def outliers(column, threshold = 3):\n",
    "    \"\"\"\n",
    "    docs\n",
    "    \"\"\"\n",
    "\n",
    "    data = column[abs(column.apply(lambda x: (x - column.mean()) / column.var() ** (1/2))) > threshold]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLV_outliers = outliers(customer_df[\"customer_lifetime_value\"])\n",
    "MPA_outliers = outliers(customer_df[\"monthly_premium_auto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = CLV_outliers.index | MPA_outliers.index # Union\n",
    "clean_customer_df = customer_df.drop(to_drop).reset_index(drop = True)\n",
    "clean_customer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "2. Create a copy of the dataframe for the data wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = clean_customer_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "3. Normalize the continuous variables. You can use any one method you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous.remove(\"months_since_policy_inception\")\n",
    "continuous.remove(\"total_claim_amount\")\n",
    "for cont_var in continuous:\n",
    "    maximum = clean_customer_df[cont_var].max()\n",
    "    minimum = clean_customer_df[cont_var].min()\n",
    "    clean_customer_df[cont_var] = clean_customer_df[cont_var].apply(lambda x: (x - minimum) / (maximum - minimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv(\"WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv\")\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "# One hot to state\n",
    "# Ordinal to coverage\n",
    "# Ordinal to employmentstatus\n",
    "# Ordinal to location code\n",
    "# One hot to marital status\n",
    "# One hot to policy type\n",
    "# One hot to policy\n",
    "# One hot to renew offercustomer_df\n",
    "# One hot to sales channel\n",
    "# One hot vehicle class\n",
    "# Ordinal vehicle size\n",
    "```\n",
    "\n",
    "```python\n",
    "customer_df.isna().sum()/len(customer_df)\n",
    "clean_customer_df[\"education\"] = clean_customer_df[\"education\"].apply(lambda x: \"Graduate\" if x in [\"Master\", \"Doctor\"] else x)\n",
    "inactive = [\"Medical Leave\", \"Disabled\", \"Retired\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_customer_df[\"employmentstatus\"] = clean_customer_df[\"employmentstatus\"].apply(lambda x: \"Inactive\" if x in inactive else x)\n",
    "clean_customer_df[\"gender\"] = clean_customer_df[\"gender\"].apply(lambda x: 1 if x == \"F\" else 0)\n",
    "clean_customer_df[\"policy\"] = clean_customer_df[\"policy\"].apply(lambda x: x[-2:])\n",
    "luxury = [\"Sports Car\", \"Luxury SUV\", \"Luxury Car\"]\n",
    "clean_customer_df[\"vehicle_class\"] = clean_customer_df[\"vehicle_class\"].apply(lambda x: \"Luxury\" if x in luxury else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy\n",
    "final_df = clean_customer_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop customer (id)\n",
    "ordinal = clean_customer_df.drop(columns = \"customer\")\n",
    "ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "4. Encode the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encoders\n",
    "# Ordinal to coverage\n",
    "# Ordinal to employmentstatus\n",
    "# Ordinal to location code\n",
    "# Ordinal vehicle size\n",
    "\n",
    "ordinal[\"coverage\"] = ordinal[\"coverage\"].map({\"Basic\" : 0, \"Extended\" : 1, \"Premium\" : 2})\n",
    "ordinal[\"employmentstatus\"] = ordinal[\"employmentstatus\"].map({\"Unemployed\" : 0, \"Inactive\" : 1, \"Employed\" : 2})\n",
    "ordinal[\"location_code\"] = ordinal[\"location_code\"].map({\"Rural\" : 0, \"Suburban\" : 1, \"Urban\" : 2})\n",
    "ordinal[\"vehicle_size\"] = ordinal[\"vehicle_size\"].map({\"Small\" : 0, \"Medsize\" : 1, \"Large\" : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = ordinal.copy()\n",
    "one_hot_colums = final_df.select_dtypes(include = object).columns[1:]\n",
    "one_hot_colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(one_hot, columns = one_hot_colums)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "5. The time variable can be useful. Try to transform its data into a useful one. Hint: Day week and month as integers might be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "6. Since the model will only accept numerical data, check and make sure that every column is numerical, if some are not, change it using encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_hot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-6487d42a2285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"day\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"day\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"week\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"week\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"month\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"month\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfinal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"effective_to_date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'one_hot' is not defined"
     ]
    }
   ],
   "source": [
    "final_df = one_hot.copy()\n",
    "final_df[\"day\"] = time_df[\"day\"]\n",
    "final_df[\"week\"] = time_df[\"week\"]\n",
    "final_df[\"month\"] = time_df[\"month\"]\n",
    "final_df = final_df.drop(columns = \"effective_to_date\")\n",
    "final_df.apply(pd.to_numeric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
